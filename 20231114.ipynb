{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a2ba32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.630556Z",
     "start_time": "2023-11-16T15:12:40.197094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import gym\n",
    "import time as time1\n",
    "import core\n",
    "#from spinup.utils.logx import EpochLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c042e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:11:14.388667Z",
     "start_time": "2023-11-16T16:11:14.386429Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0184eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:11:14.722871Z",
     "start_time": "2023-11-16T16:11:14.718704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c07090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.804888Z",
     "start_time": "2023-11-16T15:12:41.654150Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym_examples\n",
    "import envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88698551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.813820Z",
     "start_time": "2023-11-16T15:12:41.806372Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A simple FIFO experience replay buffer for DDPG agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf = np.zeros(core.combined_shape(size, obs_dim), dtype=np.float32)\n",
    "        self.obs2_buf = np.zeros(core.combined_shape(size, obs_dim), dtype=np.float32)\n",
    "        self.act_buf = np.zeros(core.combined_shape(size, act_dim), dtype=np.float32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.obs2_buf[self.ptr] = next_obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr+1) % self.max_size\n",
    "        self.size = min(self.size+1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size=32):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size) #batch_size 만큼 ReplayBuffer(D)에서 random sampling\n",
    "        batch = dict(obs=self.obs_buf[idxs],\n",
    "                     obs2=self.obs2_buf[idxs],\n",
    "                     act=self.act_buf[idxs],\n",
    "                     rew=self.rew_buf[idxs],\n",
    "                     done=self.done_buf[idxs])\n",
    "        return {k: torch.as_tensor(v, dtype=torch.float32) for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2338db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.829953Z",
     "start_time": "2023-11-16T15:12:41.815367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-20ba2ee0f664>:11: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  initial_state = np.hstack((A(time).astype('float32'),B(time).astype('float32')))\n"
     ]
    }
   ],
   "source": [
    "Fs = 10\n",
    "N = 500\n",
    "trans_info = [[{'coeff': 1.0, 'amps': 5 * np.array([-0.0154, -0.011, -0.005414]), 'freqs': [6.48e-3, 5.622e-3, 3.7e-3]},\n",
    "               {'coeff': 0.01, 'amps': 5 * np.array([0.01237, -0.005816, -0.03928]), 'freqs': [0.01758, 0.005925, 0.002652]}],\n",
    "              [{'coeff': -0.01, 'amps': 5 * np.array([-0.01568, -0.01486, -0.0064]), 'freqs': [0.00737, 0.0072, -0.0039]},\n",
    "               {'coeff': 1.0, 'amps': 5 * np.array([-0.0154, -0.011, -0.005414]), 'freqs': [6.48e-3, 5.622e-3, 3.7e-3]}]]\n",
    "A = envelope.flattop(t0=5.,len=10.,amp=1.,w=1.)\n",
    "B = envelope.flattop(t0=15.,len=30.,amp=0.8,w=1.)\n",
    "time = np.arange(N) / Fs  # (ns) \n",
    "freq = np.fft.fftfreq(N, d=1/Fs) # (GHz)\n",
    "initial_state = np.hstack((A(time).astype('float32'),B(time).astype('float32'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91edf76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.853896Z",
     "start_time": "2023-11-16T15:12:41.833063Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(id='gym_examples/Quantum', Fs=Fs, N=N, initial_state=initial_state,trans_info=trans_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ca6ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.860773Z",
     "start_time": "2023-11-16T15:12:41.856870Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d45da63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.873896Z",
     "start_time": "2023-11-16T15:12:41.862394Z"
    }
   },
   "outputs": [],
   "source": [
    "obs_dim = env.observation_space.shape #(1000,)\n",
    "act_dim = env.action_space.shape      #(1000,)\n",
    "replay_size = int(1e6)\n",
    "#Action limit\n",
    "act_limit = env.action_space.high[0] #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9f120e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.930944Z",
     "start_time": "2023-11-16T15:12:41.876635Z"
    }
   },
   "outputs": [],
   "source": [
    "ac = core.MLPActorCritic(env.observation_space, env.action_space)\n",
    "ac_targ = deepcopy(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896b17f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.936562Z",
     "start_time": "2023-11-16T15:12:41.932808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of MLPActorCritic(\n",
       "  (pi): MLPActor(\n",
       "    (pi): Sequential(\n",
       "      (0): Linear(in_features=1000, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1000, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (q): MLPQFunction(\n",
       "    (q): Sequential(\n",
       "      (0): Linear(in_features=2000, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (5): Identity()\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb4799",
   "metadata": {},
   "source": [
    "# 저렇게 만든 ac 에 대한 설명\n",
    "\n",
    "밑에서 for p in ac_targ.parameters() 이지랄한게 \n",
    "ac_targ 결국 nn.Module을 subclassing한 MLPActorCritic(nn.Module)이니까 이 안에 있는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66694f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.949826Z",
     "start_time": "2023-11-16T15:12:41.938011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze target networks with respect to optimizers (only update ia polyak averaging)\n",
    "for p in ac_targ.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "# 그냥 모든 weight and bias 가져와서 update 꺼버리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14cc589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.964257Z",
     "start_time": "2023-11-16T15:12:41.952221Z"
    }
   },
   "outputs": [],
   "source": [
    "#Experience buffer\n",
    "replay_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=replay_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc7b1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.978306Z",
     "start_time": "2023-11-16T15:12:41.966221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up function for computing DDPG Q-loss\n",
    "# 여기서 done 대신 terminated 씀\n",
    "def compute_loss_q(data):\n",
    "    o, a, r, o2, d = data['obs'], data['act'], data['rew'], data['obs2'], data['done']\n",
    "    \n",
    "    q = ac.q(o,a)\n",
    "    \n",
    "    #Bellman backup for Q function (target) \n",
    "    with torch.no_grad():\n",
    "        q_pi_targ = ac_targ.q(o2, ac_targ.pi(o2))\n",
    "        backup = r + gamma * (1-d) * q_pi_targ\n",
    "        \n",
    "    loss_q = ((q - backup)**2).mean()\n",
    "    \n",
    "    return loss_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29df0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:12:41.992271Z",
     "start_time": "2023-11-16T15:12:41.980733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up function for computing DDPG pi loss\n",
    "def compute_loss_pi(data):\n",
    "    o = data['obs']\n",
    "    q_pi = ac.q(o, ac.pi(o))\n",
    "    return -q_pi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c30e9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:14:58.926800Z",
     "start_time": "2023-11-16T15:14:58.922085Z"
    }
   },
   "outputs": [],
   "source": [
    "#ddpg 내부에서 정의된 parameter\n",
    "seed = 0\n",
    "steps_per_epoch = 4000\n",
    "epochs = 100\n",
    "replay_size = int(1e6)\n",
    "gamma = 0.99\n",
    "polyak = 0.995\n",
    "pi_lr = 1e-3\n",
    "q_lr = 1e-3\n",
    "batch_size = 100\n",
    "start_steps = 10000\n",
    "update_after = 1000\n",
    "update_every=50\n",
    "act_noise = 0.1\n",
    "max_ep_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60ad3ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T15:14:59.322768Z",
     "start_time": "2023-11-16T15:14:59.319170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up optimizers for policy and q-function\n",
    "pi_optimizer = Adam(ac.pi.parameters(), lr=pi_lr)\n",
    "q_optimizer = Adam(ac.q.parameters(), lr=q_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37edc2c",
   "metadata": {},
   "source": [
    "# Set up model saving\n",
    "\n",
    "logger 없이 어떻게 하지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18a56a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:02:05.495631Z",
     "start_time": "2023-11-16T16:02:05.489072Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(data):\n",
    "# First run one gradient descent step for Q.\n",
    "    q_optimizer.zero_grad()\n",
    "    loss_q = compute_loss_q(data)\n",
    "    loss_q.backward()\n",
    "    q_optimizer.step()\n",
    "\n",
    "    # Freeze Q-network so you don't waste computational effort \n",
    "    # computing gradients for it during the policy learning step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Next run one gradient descent step for pi.\n",
    "    pi_optimizer.zero_grad()\n",
    "    loss_pi = compute_loss_pi(data)\n",
    "    loss_pi.backward()\n",
    "    pi_optimizer.step()\n",
    "\n",
    "    # Unfreeze Q-network so you can optimize it at next DDPG step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # Record things\n",
    "    #logger.store(LossQ=loss_q.item(), LossPi=loss_pi.item(), **loss_info)\n",
    "\n",
    "    # Finally, update target networks by polyak averaging.\n",
    "    with torch.no_grad():\n",
    "        for p, p_targ in zip(ac.parameters(), ac_targ.parameters()):\n",
    "            # NB: We use an in-place operations \"mul_\", \"add_\" to update target\n",
    "            # params, as opposed to \"mul\" and \"add\", which would make new tensors.\n",
    "            p_targ.data.mul_(polyak)\n",
    "            p_targ.data.add_((1 - polyak) * p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7bf28d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:09:52.201849Z",
     "start_time": "2023-11-16T16:09:52.198139Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_action(o, noise_scale):\n",
    "    a = ac.act(torch.as_tensor(o, dtype=torch.float32))\n",
    "    a += noise_scale * np.random.randn(act_dim)\n",
    "    return np.clip(a, -act_limit, act_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "361a2f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:09:52.481806Z",
     "start_time": "2023-11-16T16:09:52.477733Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_agent():\n",
    "    for j in range(num_test_episodes):\n",
    "        o, d, ep_ret, ep_len = test_env.reset(), False, 0, 0\n",
    "        while not(d or (ep_len == max_ep_len)):\n",
    "        # Take deterministic actions at test time (noise_scale=0)\n",
    "            o, r, d, _ = test_env.step(get_action(o, 0))\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "        logger.store(TestEpRet=ep_ret, TestEpLen=ep_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f54eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:02:06.111383Z",
     "start_time": "2023-11-16T16:02:06.107968Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare for interaction with environment\n",
    "total_steps = steps_per_epoch * epochs\n",
    "#start_time = time1.time()\n",
    "o, ep_ret, ep_len = env.reset()[0], 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74774ac6",
   "metadata": {},
   "source": [
    "# 지금부터는 main  loop 입니당 호호호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ff49a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:06:22.132932Z",
     "start_time": "2023-11-16T16:02:06.513827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_action' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2621c2041e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_action' is not defined"
     ]
    }
   ],
   "source": [
    "for t in range(total_steps):\n",
    "    \n",
    "    if t > start_steps:\n",
    "        a = get_action(o, act_noise)\n",
    "    else:\n",
    "        a = env.action_space.sample()\n",
    "    \n",
    "    # Step the env   d : terminated, _ :truncated=False, i : info={} \n",
    "    o2, r, d, _, i = env.step(a)\n",
    "    ep_ret += r\n",
    "    ep_len += 1\n",
    "    \n",
    "    # Ignoring done if 강제로 종료당하면 d = False 유지\n",
    "    d = False if ep_len==max_ep_len else d\n",
    "    \n",
    "    replay_buffer.store(o, a, r, o2, d)\n",
    "    \n",
    "    o = o2\n",
    "    \n",
    "    # End of trajectory handling\n",
    "    if d or (ep_len == max_ep_len):\n",
    "        #logger.store(EpRet = ep_ret, Eplen = ep_len)\n",
    "        o, ep_ret, ep_len = env.reset()[0], 0, 0\n",
    "    \n",
    "    # Update handling\n",
    "    if t >= update_after and t % update_every == 0:\n",
    "        for _ in range(update_every):\n",
    "            batch = replay_buffer.sample_batch(batch_size)\n",
    "            update(data=batch)\n",
    "    \n",
    "    # End of epoch handling\n",
    "    if (t+1) % steps_per_epoch == 0:\n",
    "        epoch = (t+1) // steps_per_epoch\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dec85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:06:22.134524Z",
     "start_time": "2023-11-16T16:02:06.368Z"
    }
   },
   "outputs": [],
   "source": [
    "a=env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe62b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:06:22.135266Z",
     "start_time": "2023-11-16T16:02:06.582Z"
    }
   },
   "outputs": [],
   "source": [
    "o2, r, d, _, i = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c292fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T03:09:22.613013Z",
     "start_time": "2023-11-16T03:09:22.609149Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d664dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
